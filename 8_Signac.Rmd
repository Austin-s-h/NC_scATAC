
```{r}
library(renv)
renv::activate()
# install.packages("SeuratObject")
# devtools::install_github("stuart-lab/signac", ref = "1.12.0")
# apparently TSS bug is fixed in development version
# remotes::install_github("stuart-lab/signac", ref = "develop")
# install.packages("BSgenome.Ggallus.ENSEMBL.galGal6_1.0.3.tar.gz", repos = NULL)

suppressPackageStartupMessages({
  library(BSgenome.Ggallus.ENSEMBL.galGal6)
  library(GenomicFeatures)
  library(RMariaDB)
  library(org.Gg.eg.db)
  library(dplyr)
  library(JASPAR2020)
  library(Seurat) # 5
  library(Signac)
  library(ggplot2)
  library(AnnotationHub)
  library(ensembldb)
  library(Biostrings)
  library(Matrix) # 1.6.4
  library(irlba)
})
plan("multicore", workers = 24)
ah <- AnnotationHub()
qr <- query(ah, c("EnsDb", "gallus gallus", "95"))
EnsDb_gg6 <- ah[["AH67945"]]
# extract gene annotations from EnsDb
annotations <- suppressWarnings(GetGRangesFromEnsDb(ensdb = EnsDb_gg6))
```

```{r}
seurat_list <- list()
bins <- unlist(tileGenome(seqlengths = seqlengths(EnsDb_gg6), tilewidth = 5000))

for (s in c("HH6", "HH8", "HH10", "HH12", "HH14", "HH16", "HH18")) {
  prefix <- "data/10xscATAC_Lane1_Lane2_outs/"
  fragpath <- c(paste0(prefix, s, "/", s, "_fragments.tsv.gz"))
  input_csv_file <- c(paste0(prefix, s, "/", s, "_singlecell.csv"))
  # Load data
  print(paste0("Reading ", fragpath, " and ", input_csv_file))
  metadata <- read.csv(file = input_csv_file, header = TRUE, row.names = 1)
  print(paste0("Creating Seurat object from", nrow(metadata), " unfiltered cells cells."))
  # Create a fragment object
  barcode_names <- rownames(metadata[which(metadata$is__cell_barcode == 1), ])
  print(paste0("Creating fragment object with ", length(barcode_names), " cells. (Prefiltered from 10X Genomics)"))
  frags <- CreateFragmentObject(path = fragpath, cells = barcode_names)
  # counts <- FeatureMatrix(fragments = frags, features = bins, cells = barcode_names)
  counts <- GenomeBinMatrix(fragments = frags, genome = seqinfo(EnsDb_gg6),
    cells = barcode_names, binsize = 5000, process_n = 2000, sep = c("-", "-"),
    verbose = TRUE)
  count_name_gr <-  StringToGRanges(rownames(counts), sep = c("-", "-"))
  # Create a chromatin object
  assay <- CreateChromatinAssay(counts = counts,
    min.features = 1000,
    ranges = count_name_gr,
    fragments = frags,
    annotation = annotations,
    genome = seqinfo(EnsDb_gg6)
  )
  seurat <- CreateSeuratObject(
    counts = assay,
    assay = "bins5000",
    project = paste0(s, "_ATAC"),
    meta.data = metadata
  )
  # Add the Seurat object to the list
  seurat_list[[s]] <- seurat
}

# Add in the additional HH6_NPB and HH18_SORT cells atac signal from multiome
for (s in c("HH6_NPB", "HH18_SORT")) {
  prefix <- c(paste0(s, "_Multiome_95/outs/"))
  fragpath <- c(paste0(prefix,"atac_fragments.tsv.gz"))
  input_csv_file <- c(paste0(prefix, "filtered_feature_bc_matrix/barcodes.tsv.gz"))
  # Load data
  print(paste0("Reading ", fragpath, " and ", input_csv_file))
  barcode_names <- read.csv(file = input_csv_file, header = FALSE)
  barcode_names <- barcode_names[,1]
  print(paste0("Creating fragment object with ", length(barcode_names),
    " cells. (Prefiltered from 10X Genomics)"))
  frags <- CreateFragmentObject(path = fragpath, cells = barcode_names)
  # counts <- FeatureMatrix(fragments = frags, features = bins, cells = barcode_names)
  counts <- GenomeBinMatrix(fragments = frags, genome = seqinfo(EnsDb_gg6),
    cells = barcode_names, binsize = 5000, process_n = 2000, sep = c("-", "-"),
    verbose = TRUE)
  count_name_gr <-  StringToGRanges(rownames(counts), sep = c("-", "-"))
  # Create a Chromatin assay
  assay <- CreateChromatinAssay(counts = counts,
    ranges = count_name_gr,
    fragments = frags,
    annotation = annotations,
    genome = seqinfo(EnsDb_gg6)
  )
  seurat <- CreateSeuratObject(
    counts = assay,
    assay = "bins5000",
    project = paste0(s, "_ATAC"),
  )
  # Add the Seurat object to the list
  seurat_list[[s]] <- seurat
}

saveRDS(seurat_list, file = "data/seurat_list_3.rds", compress = FALSE)
```

```{r}
# fpath <- system.file("extdata", "fragments.tsv.gz", package="Signac")
# Fragments(atac_small) <- NULL
# Fragments(atac_small) <- CreateFragmentObject(
#   path = fpath,
#   cells = colnames(atac_small),
#   tolerance = 0.5
# )
# atac_small <- TSSEnrichment(atac_small, fast = FALSE)
```

Probably want to re-call peaks across the entire dataset after integration?
```{r}
options(future.globals.maxSize = 20 * 1024 ^ 3)  # set to 20 Gb
seurat_list <- readRDS(file = "data/seurat_list_3.rds")

# Previously used first pass QC metrics
# "HH8", "HH10", "HH12", "HH14", "HH16", "HH18", "HH6_NPB", "HH18_SORT"
for (s in c("HH6", "HH8", "HH10", "HH12", "HH14", "HH16", "HH18", "HH6_NPB", "HH18_SORT")) {
  seurat_obj <- seurat_list[[s]]
  head(seurat_obj@meta.data)
  seurat_obj <- NucleosomeSignal(seurat_obj)
  seurat_obj$nucleosome_group <- ifelse(seurat_obj$nucleosome_signal > 4, 'NS > 4', 'NS < 4')
  FragmentHistogram(object = seurat_obj, group.by = 'nucleosome_group', region = '1-1-100000')
  seurat_obj <- TSSEnrichment(seurat_obj, fast = FALSE)
  seurat_obj$high.tss <- ifelse(seurat_obj$TSS.enrichment > 2, 'High', 'Low')
  tss <- TSSPlot(seurat_obj, group.by = 'high.tss') + NoLegend()
  ggsave(tss, filename = paste0("export/", s, "_QC_TSS.pdf"), width = 8, height = 8)
  vln <- VlnPlot(
    object = seurat_obj,
    features = c('TSS.enrichment', 'nFeature_bins5000',
                 'mitochondrial','TSS.percentile'),
    pt.size = 0.1,
    ncol = 5
  )
  ggsave(vln, filename = paste0("export/", s, "_QC_violin.pdf"), width = 12, height = 8)
  seurat_obj <- BinarizeCounts(seurat_obj)
  # remove features that are very low counts
  seurat_obj <- subset(
    x = seurat_obj,
    subset = nFeature_bins5000 > 5
  )
  seurat_obj <- RunTFIDF(seurat_obj)
  seurat_obj <- FindTopFeatures(seurat_obj, min.cutoff = 'q20')
  seurat_obj <- RunSVD(object = seurat_obj)
  DepthCor(seurat_obj)

  seurat_obj <- RunUMAP(
    object = seurat_obj,
    reduction = 'lsi',
    dims = 2:30, 
  )
  seurat_obj <- FindNeighbors(
    object = seurat_obj,
    reduction = 'lsi',
    dims = 2:30
  )
  seurat_obj <- FindClusters(
    object = seurat_obj,
    algorithm = 2,
    resolution = 0.5,
    verbose = FALSE
  )


  umap <- DimPlot(object = seurat_obj, label = TRUE, reduction = "umap") + NoLegend()
  ggsave(umap, filename = paste0("export/", s, "pre_filter_UMAP.pdf"), width = 8, height = 8)
  seurat_obj <- subset(
    x = seurat_obj,
    subset = nFeature_bins5000 > 1250 &
      nFeature_bins5000 < 100000 &
      nucleosome_signal < 4 &
      TSS.enrichment > 2
  )
  outdir <- paste0("export/peaks/", s, "_macs2")
  if (!dir.exists(outdir)) {
    dir.create(outdir, recursive = TRUE)
  }
  # grouping by timepoint only
  peaks <- CallPeaks(seurat_obj,
                     group.by = NULL,
                     macs2.path = "/home/vscode/.local/bin/macs2",
                     effective.genome.size = 1218492533,
                     outdir = paste0("export/peaks/", s, "_macs2"),
                     extsize = 73, shift = 37,
                     additional.args = "--nomodel",
                     cleanup = FALSE,
                     name = paste0(s, "prefiltered_macs2"))
  saveRDS(peaks, file = paste0("export/peaks/",s,"_macs2/peaks.rds"), compress = FALSE)

  seurat_list[[s]] <- seurat_obj
}

saveRDS(seurat_list, file = "data/seurat_list_4.rds", compress = FALSE)
```




```{r}
# Normalize the data
seurat_list <- lapply(seurat_list, function(x) {
  NormalizeData(x, normalization.method = "LogNormalize", scale.factor = 10000)
})

# Find variable features
seurat_list <- lapply(seurat_list, function(x) {
  FindVariableFeatures(x, selection.method = "vst", nfeatures = 2000)
})

# Identify anchors+
anchors <- FindIntegrationAnchors(object.list = seurat_list, dims = 1:30)

# Integrate the data
integrated <- IntegrateData(anchorset = anchors, dims = 1:30)
```

```{r}
# Compute metrics
seurat_obj <- PercentageFeatureSet(seurat_obj, pattern = "^MT", col.name = "percent.mt")

# Normalize the data
seurat_obj <- NormalizeData(seurat_obj, normalization.method = "LogNormalize", scale.factor = 10000)

# Find variable features
seurat_obj <- FindVariableFeatures(seurat_obj, selection.method = "vst", nfeatures = 2000)

# Scale the data
all.genes <- rownames(seurat_obj)
seurat_obj <- ScaleData(seurat_obj, features = all.genes)

# Perform linear dimensional reduction
seurat_obj <- RunPCA(seurat_obj, features = VariableFeatures(object = seurat_obj))

# Cluster the cells
seurat_obj <- FindNeighbors(seurat_obj, dims = 1:10)
seurat_obj <- FindClusters(seurat_obj, resolution = 0.5)

# Run non-linear dimensional reduction (UMAP/tSNE)
seurat_obj <- RunUMAP(seurat_obj, dims = 1:10)
seurat_obj <- RunTSNE(seurat_obj, dims = 1:10)

# Visualize the data
DimPlot(seurat_obj, reduction = "umap")
DimPlot(seurat_obj, reduction = "tsne")
```